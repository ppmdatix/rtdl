{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "underlying-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements:\n",
    "# !pip install rtdl\n",
    "# !pip install libzero==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "scheduled-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bigger-frame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123456"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# Docs: https://yura52.github.io/zero/0.0.4/reference/api/zero.improve_reproducibility.html\n",
    "zero.improve_reproducibility(seed=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-contractor",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addressed-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/adult_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.values\n",
    "\n",
    "target = df[\"target\"].values\n",
    "targetValues = list(set(target))\n",
    "targetMapping = dict()\n",
    "\n",
    "\n",
    "for i in range(len(targetValues)):\n",
    "    targetMapping[targetValues[i]] = i\n",
    "\n",
    "result = []\n",
    "for t in target:\n",
    "    result.append(targetMapping[t])\n",
    "\n",
    "dfFormat = {\"target\": pd.DataFrame(result).values.reshape(df.shape[0]), \"data\": df.drop(\"target\", axis=1), \"frame\": None, \"DESCR\": \"Todo\", \"feature_names\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabulous-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toY(_data):\n",
    "    if type(_data) == np.ndarray:\n",
    "        return _data\n",
    "    else:\n",
    "        return _data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uniform-shield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'>50K': 0, '<=50K': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "streaming-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'multiclass'\n",
    "\n",
    "assert task_type in ['binclass', 'multiclass', 'regression']\n",
    "\n",
    "X_all = dfFormat['data'].astype('float32')\n",
    "y_all = dfFormat['target'].astype('float32' if task_type == 'regression' else 'int64')\n",
    "if task_type != 'regression':\n",
    "    y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype('int64')\n",
    "n_classes = int(max(y_all)) + 1 if task_type == 'multiclass' else None\n",
    "\n",
    "oldX = {}\n",
    "y = {}\n",
    "oldX['train'], oldX['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
    "    X_all, y_all, train_size=0.8\n",
    ")\n",
    "oldX['train'], oldX['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
    "    oldX['train'], y['train'], train_size=0.8\n",
    ")\n",
    "\n",
    "# not the best way to preprocess features, but enough for the demonstration\n",
    "preprocess = sklearn.preprocessing.StandardScaler().fit(oldX['train'])\n",
    "X = {\n",
    "    # k: torch.tensor(v, device=device)\n",
    "    k: torch.tensor(preprocess.fit_transform(v), device=device)\n",
    "    for k, v in oldX.items()\n",
    "}\n",
    "# y = {k: torch.tensor(np.array(v), device=device) for k, v in y.items()}\n",
    "y = {k: torch.tensor(toY(v), device=device) for k, v in y.items()}\n",
    "\n",
    "# !!! CRUCIAL for neural networks when solving regression problems !!!\n",
    "if task_type == 'regression':\n",
    "    y_mean = y['train'].mean().item()\n",
    "    y_std = y['train'].std().item()\n",
    "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
    "else:\n",
    "    y_std = y_mean = None\n",
    "\n",
    "if task_type != 'multiclass':\n",
    "    y = {k: v.float() for k, v in y.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-idaho",
   "metadata": {},
   "source": [
    "### Model\n",
    "Carefully read the comments and uncomment the code for the model you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greatest-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    d_out = n_classes or 1\n",
    "\n",
    "\n",
    "    first_layer = 4\n",
    "    _model = rtdl.MLP.make_baseline(\n",
    "        d_in=X_all.shape[1],\n",
    "    #     d_layers=[first_layer, 256, 128],\n",
    "        d_layers=[first_layer, 8, first_layer],\n",
    "        dropout=0.1,\n",
    "        d_out=d_out,\n",
    "        # seed=42\n",
    "    )\n",
    "    lr = 0.001\n",
    "    weight_decay = 0.0\n",
    "\n",
    "    # model = rtdl.ResNet.make_baseline(\n",
    "    #     d_in=X_all.shape[1],\n",
    "    #     d_main=128,\n",
    "    #     d_intermidiate=256,\n",
    "    #     dropout_first=0.2,\n",
    "    #     dropout_second=0.0,\n",
    "    #     n_blocks=2,\n",
    "    #     d_out=d_out,\n",
    "    # )\n",
    "    # lr = 0.001\n",
    "    # weight_decay = 0.0\n",
    "\n",
    "    # model = rtdl.FTTransformer.make_default(\n",
    "    #     n_num_features=X_all.shape[1],\n",
    "    #     cat_cardinalities=None,\n",
    "    #     last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
    "    #     d_out=d_out,\n",
    "    # )\n",
    "\n",
    "    # === ABOUT CATEGORICAL FEATURES ===\n",
    "    # IF you use MLP, ResNet or any other simple feed-forward model (NOT transformer-based model)\n",
    "    # AND there are categorical features\n",
    "    # THEN you have to implement a wrapper that handles categorical features.\n",
    "    # The example below demonstrates how it can be achieved using rtdl.CategoricalFeatureTokenizer.\n",
    "    # ==================================\n",
    "    # 1. When you have both numerical and categorical features, you should prepare you data like this:\n",
    "    #    (X_num<float32>, X_cat<int64>) instead of X<float32>\n",
    "    #    Each column in X_cat should contain values within the range from 0 to <(the number of unique values in column) - 1>;\n",
    "    #    use sklean.preprocessing.OrdinalEncoder to achieve this;\n",
    "    # 2. Prepare a list of so called \"cardinalities\":\n",
    "    #    cardinalities[i] = <the number of unique values of the i-th categorical feature>\n",
    "    # 3. See the commented example below and adapt it for your needs.\n",
    "    #\n",
    "    # class Model(nn.Module):\n",
    "    #     def __init__(\n",
    "    #         self,\n",
    "    #         n_num_features: int,\n",
    "    #         cat_tokenizer: rtdl.CategoricalFeatureTokenizer,\n",
    "    #         mlp_kwargs: Dict[str, Any],\n",
    "    #     ):\n",
    "    #         super().__init__()\n",
    "    #         self.cat_tokenizer = cat_tokenizer\n",
    "    #         self.model = rtdl.MLP.make_baseline(\n",
    "    #             d_in=n_num_features + cat_tokenizer.n_tokens * cat_tokenizer.d_token,\n",
    "    #             **mlp_kwargs,\n",
    "    #         )\n",
    "    #\n",
    "    #     def forward(self, x_num, x_cat):\n",
    "    #         return self.model(\n",
    "    #             torch.cat([x_num, self.cat_tokenizer(x_cat).flatten(1, -1)], dim=1)\n",
    "    #         )\n",
    "    #\n",
    "    # model = Model(\n",
    "    #     # `None` means \"Do not transform numerical features\"\n",
    "    #     # `d_token` is the size of embedding for ONE categorical feature\n",
    "    #     X_num_all.shape[1],\n",
    "    #     rtdl.CategoricalFeatureTokenizer(cardinalities, d_token, True, 'uniform'),\n",
    "    #     mlp_kwargs,\n",
    "    # )\n",
    "    # Then the model should be used as `model(x_num, x_cat)` instead of of `model(x)`.\n",
    "\n",
    "    _model.to(device)\n",
    "    optimizer = (\n",
    "        _model.make_default_optimizer()\n",
    "        if isinstance(_model, rtdl.FTTransformer)\n",
    "    #     else torch.optim.AdamW(_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else torch.optim.Adam(_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    )\n",
    "    loss_fn = (\n",
    "        F.binary_cross_entropy_with_logits\n",
    "        if task_type == 'binclass'\n",
    "        else F.cross_entropy\n",
    "        if task_type == 'multiclass'\n",
    "        else F.mse_loss\n",
    "    )\n",
    "    return _model, optimizer, loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convinced-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, loss_fn = createModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-monday",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inclusive-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.2394\n"
     ]
    }
   ],
   "source": [
    "def apply_model(x_num, x_cat=None, model=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num, x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part, model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(X[part], 1024):\n",
    "        prediction.append(apply_model(batch,model=model))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "\n",
    "    if task_type == 'binclass':\n",
    "        prediction = np.round(scipy.special.expit(prediction))\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    elif task_type == 'multiclass':\n",
    "        prediction = prediction.argmax(1)\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    else:\n",
    "        assert task_type == 'regression'\n",
    "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "# Docs: https://yura52.github.io/zero/reference/api/zero.data.IndexLoader.html\n",
    "batch_size = 256\n",
    "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "# Docs: https://yura52.github.io/zero/reference/api/zero.ProgressTracker.html\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\",model):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "annual-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotLosses(_losses, title=\"this is a graph\"):\n",
    "    for key in _losses:\n",
    "        plt.plot([np.log(x) for x in _losses[key]], label=key)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "personalized-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnThat(_model, _optimizer, _loss_fn, _evaluate, _progress,_X, _y, _epochs, _batch_size,_train_loader, _relational_batch, _old_X, print_mode):\n",
    "\n",
    "    report_frequency = len(X['train']) // _batch_size // 5\n",
    "    losses = dict()\n",
    "    losses['val']  = []\n",
    "    losses['test'] = []\n",
    "    for epoch in range(1, _epochs + 1):\n",
    "        for iteration, batch_idx in enumerate(train_loader):\n",
    "            _model.train()\n",
    "            _optimizer.zero_grad()\n",
    "            x_batch = _X['train'][batch_idx]\n",
    "            y_batch = _y['train'][batch_idx]\n",
    "            loss = _loss_fn(apply_model(x_batch,model=_model).squeeze(1), y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            factors = dict()\n",
    "\n",
    "            ## Modify gradients\n",
    "            if _relational_batch:\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name==\"blocks.0.linear.weight\":                    \n",
    "                        column_count = df.shape[1] - 1\n",
    "                        factors = torch.ones(column_count,param.grad.shape[0])\n",
    "                        for i in range(column_count):\n",
    "                            column = oldX['train'].columns[i]\n",
    "                            if True:# not column in oldNames:\n",
    "                                idx = oldX['train'][iteration * batch_size:(iteration+1) * batch_size].columns[i]\n",
    "                                realCount = oldX['train'][iteration * batch_size:(iteration+1) * batch_size][idx].sum()\n",
    "                                if realCount > 0:\n",
    "                                    factors[i] = (batch_size / (1.0 * realCount)) * factors[i]\n",
    "                                else:\n",
    "                                    ()\n",
    "                                    # factors[i] = float('nan') * factors[i] \n",
    "                        param.grad = torch.mul(param.grad, torch.transpose(factors,0,1))\n",
    "\n",
    "            optimizer.step()\n",
    "            if iteration % report_frequency == 0:\n",
    "                batch = \"batch\"\n",
    "                if relational_batch:\n",
    "                    batch= \"relational-batch\"\n",
    "                print(f'(epoch) {epoch} ({batch}) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        losses['val'].append(float(loss_fn(apply_model(X['val'],model=_model).squeeze(1), y['val'])))\n",
    "        losses['test'].append(float(loss_fn(apply_model(X['test'],model=_model).squeeze(1), y['test'])))\n",
    "\n",
    "\n",
    "        val_score  = _evaluate('val',_model)\n",
    "        test_score = _evaluate('test',_model)\n",
    "        print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "        _progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "        if _progress.success:\n",
    "            print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "        print()\n",
    "        if _progress.fail:\n",
    "            break\n",
    "    if print_mode:\n",
    "        plotLosses(losses, \"relational batch ? \" + str(_relational_batch))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numerous-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "relational_batch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-booth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 1 (relational-batch) 0 (loss) 0.7305\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7053\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.6830\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.6704\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.6504\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.6433\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.6393\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.6289\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.6055\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.6023\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.5689\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.5586\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.5565\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.5228\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.4756\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4698\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.4213\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4350\n",
      "Epoch 003 | Validation score: 0.8259 | Test score: 0.8283 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4442\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4326\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3623\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.3961\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3558\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.3997\n",
      "Epoch 004 | Validation score: 0.8326 | Test score: 0.8359 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4029\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4142\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3246\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.3772\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3541\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.4026\n",
      "Epoch 005 | Validation score: 0.8336 | Test score: 0.8349 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4140\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.3915\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3412\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3918\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3648\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3851\n",
      "Epoch 006 | Validation score: 0.8322 | Test score: 0.8346\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.3884\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3835\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3340\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3796\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3454\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3747\n",
      "Epoch 007 | Validation score: 0.8330 | Test score: 0.8351\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.3969\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3853\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3349\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3709\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3541\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3542\n",
      "Epoch 008 | Validation score: 0.8319 | Test score: 0.8353\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4103\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.3966\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3171\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3784\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3512\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3652\n",
      "Epoch 009 | Validation score: 0.8321 | Test score: 0.8346\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.3994\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3800\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3377\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3951\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3703\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3563\n",
      "Epoch 010 | Validation score: 0.8292 | Test score: 0.8337\n"
     ]
    }
   ],
   "source": [
    "losses_rb = learnThat(\n",
    "    _model    =model, \n",
    "    _optimizer=optimizer, \n",
    "    _loss_fn  =loss_fn, \n",
    "    _evaluate =evaluate, \n",
    "    _progress =progress,\n",
    "    _X=X, \n",
    "    _y=y, \n",
    "    _epochs      =epochs, \n",
    "    _batch_size  =batch_size,\n",
    "    _train_loader=train_loader, \n",
    "    _relational_batch=relational_batch, \n",
    "    _old_X=oldX,\n",
    "    print_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tight-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, loss_fn = createModel()\n",
    "epochs = 10\n",
    "relational_batch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "external-animal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 1 (batch) 0 (loss) 0.9006\n",
      "(epoch) 1 (batch) 16 (loss) 0.8593\n",
      "(epoch) 1 (batch) 32 (loss) 0.8402\n",
      "(epoch) 1 (batch) 48 (loss) 0.7820\n",
      "(epoch) 1 (batch) 64 (loss) 0.7722\n",
      "(epoch) 1 (batch) 80 (loss) 0.7280\n",
      "Epoch 001 | Validation score: 0.3622 | Test score: 0.3527\n",
      "(epoch) 2 (batch) 0 (loss) 0.7162\n",
      "(epoch) 2 (batch) 16 (loss) 0.6626\n",
      "(epoch) 2 (batch) 32 (loss) 0.5894\n",
      "(epoch) 2 (batch) 48 (loss) 0.5770\n",
      "(epoch) 2 (batch) 64 (loss) 0.5065\n",
      "(epoch) 2 (batch) 80 (loss) 0.4898\n",
      "Epoch 002 | Validation score: 0.8134 | Test score: 0.8171\n",
      "(epoch) 3 (batch) 0 (loss) 0.4754\n",
      "(epoch) 3 (batch) 16 (loss) 0.4639\n",
      "(epoch) 3 (batch) 32 (loss) 0.3675\n",
      "(epoch) 3 (batch) 48 (loss) 0.4283\n",
      "(epoch) 3 (batch) 64 (loss) 0.3741\n",
      "(epoch) 3 (batch) 80 (loss) 0.3964\n",
      "Epoch 003 | Validation score: 0.8351 | Test score: 0.8313 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 4 (batch) 0 (loss) 0.4192\n",
      "(epoch) 4 (batch) 16 (loss) 0.4229\n",
      "(epoch) 4 (batch) 32 (loss) 0.3515\n",
      "(epoch) 4 (batch) 48 (loss) 0.4195\n",
      "(epoch) 4 (batch) 64 (loss) 0.3628\n",
      "(epoch) 4 (batch) 80 (loss) 0.3810\n",
      "Epoch 004 | Validation score: 0.8336 | Test score: 0.8302\n",
      "(epoch) 5 (batch) 0 (loss) 0.4272\n",
      "(epoch) 5 (batch) 16 (loss) 0.3963\n",
      "(epoch) 5 (batch) 32 (loss) 0.3501\n",
      "(epoch) 5 (batch) 48 (loss) 0.3961\n",
      "(epoch) 5 (batch) 64 (loss) 0.3654\n",
      "(epoch) 5 (batch) 80 (loss) 0.3911\n",
      "Epoch 005 | Validation score: 0.8324 | Test score: 0.8313\n",
      "(epoch) 6 (batch) 0 (loss) 0.4007\n",
      "(epoch) 6 (batch) 16 (loss) 0.4100\n",
      "(epoch) 6 (batch) 32 (loss) 0.3577\n",
      "(epoch) 6 (batch) 48 (loss) 0.3932\n",
      "(epoch) 6 (batch) 64 (loss) 0.3619\n",
      "(epoch) 6 (batch) 80 (loss) 0.3903\n",
      "Epoch 006 | Validation score: 0.8296 | Test score: 0.8308\n",
      "(epoch) 7 (batch) 0 (loss) 0.4014\n",
      "(epoch) 7 (batch) 16 (loss) 0.3768\n",
      "(epoch) 7 (batch) 32 (loss) 0.3199\n",
      "(epoch) 7 (batch) 48 (loss) 0.3969\n",
      "(epoch) 7 (batch) 64 (loss) 0.3518\n",
      "(epoch) 7 (batch) 80 (loss) 0.3768\n",
      "Epoch 007 | Validation score: 0.8307 | Test score: 0.8310\n",
      "(epoch) 8 (batch) 0 (loss) 0.4094\n",
      "(epoch) 8 (batch) 16 (loss) 0.4006\n",
      "(epoch) 8 (batch) 32 (loss) 0.3496\n",
      "(epoch) 8 (batch) 48 (loss) 0.4031\n",
      "(epoch) 8 (batch) 64 (loss) 0.3762\n",
      "(epoch) 8 (batch) 80 (loss) 0.3749\n",
      "Epoch 008 | Validation score: 0.8307 | Test score: 0.8325\n",
      "(epoch) 9 (batch) 0 (loss) 0.4065\n",
      "(epoch) 9 (batch) 16 (loss) 0.4033\n",
      "(epoch) 9 (batch) 32 (loss) 0.3647\n",
      "(epoch) 9 (batch) 48 (loss) 0.3863\n",
      "(epoch) 9 (batch) 64 (loss) 0.3564\n",
      "(epoch) 9 (batch) 80 (loss) 0.3883\n",
      "Epoch 009 | Validation score: 0.8296 | Test score: 0.8299\n",
      "(epoch) 10 (batch) 0 (loss) 0.4233\n",
      "(epoch) 10 (batch) 16 (loss) 0.3868\n",
      "(epoch) 10 (batch) 32 (loss) 0.3276\n",
      "(epoch) 10 (batch) 48 (loss) 0.3808\n",
      "(epoch) 10 (batch) 64 (loss) 0.3526\n",
      "(epoch) 10 (batch) 80 (loss) 0.3713\n",
      "Epoch 010 | Validation score: 0.8299 | Test score: 0.8320\n"
     ]
    }
   ],
   "source": [
    "losses_norb = learnThat(\n",
    "    _model    =model, \n",
    "    _optimizer=optimizer, \n",
    "    _loss_fn  =loss_fn, \n",
    "    _evaluate =evaluate, \n",
    "    _progress =progress,\n",
    "    _X=X, \n",
    "    _y=y, \n",
    "    _epochs      =epochs, \n",
    "    _batch_size  =batch_size,\n",
    "    _train_loader=train_loader, \n",
    "    _relational_batch=relational_batch, \n",
    "    _old_X=oldX,\n",
    "    print_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "narrow-anxiety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 1 (relational-batch) 0 (loss) 0.6402\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.6158\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.5738\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.5705\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.5113\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.5046\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.4880\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.4671\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.4089\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.4469\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4023\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4251\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4191\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.3992\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3555\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4135\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3481\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4044\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4154\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.3906\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3617\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4248\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3602\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4000\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4298\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.3949\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3585\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4050\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3659\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3990\n",
      "Epoch 005 | Validation score: 0.8294 | Test score: 0.8337\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.3972\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4144\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3660\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.4151\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3381\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3760\n",
      "Epoch 006 | Validation score: 0.8315 | Test score: 0.8351\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4035\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3894\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3625\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.4086\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3468\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3913\n",
      "Epoch 007 | Validation score: 0.8322 | Test score: 0.8366\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.3956\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3939\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3698\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3968\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3423\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3662\n",
      "Epoch 008 | Validation score: 0.8340 | Test score: 0.8380\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4049\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4025\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3535\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3978\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3397\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3630\n",
      "Epoch 009 | Validation score: 0.8330 | Test score: 0.8399\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.3967\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3846\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3482\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3954\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3495\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3806\n",
      "Epoch 010 | Validation score: 0.8319 | Test score: 0.8392\n",
      "(epoch) 1 (batch) 0 (loss) 0.7556\n",
      "(epoch) 1 (batch) 16 (loss) 0.7427\n",
      "(epoch) 1 (batch) 32 (loss) 0.7359\n",
      "(epoch) 1 (batch) 48 (loss) 0.7189\n",
      "(epoch) 1 (batch) 64 (loss) 0.6950\n",
      "(epoch) 1 (batch) 80 (loss) 0.6530\n",
      "Epoch 001 | Validation score: 0.6428 | Test score: 0.6472\n",
      "(epoch) 2 (batch) 0 (loss) 0.6435\n",
      "(epoch) 2 (batch) 16 (loss) 0.5986\n",
      "(epoch) 2 (batch) 32 (loss) 0.5228\n",
      "(epoch) 2 (batch) 48 (loss) 0.5286\n",
      "(epoch) 2 (batch) 64 (loss) 0.4419\n",
      "(epoch) 2 (batch) 80 (loss) 0.4397\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4762\n",
      "(epoch) 3 (batch) 16 (loss) 0.4357\n",
      "(epoch) 3 (batch) 32 (loss) 0.3758\n",
      "(epoch) 3 (batch) 48 (loss) 0.4570\n",
      "(epoch) 3 (batch) 64 (loss) 0.3966\n",
      "(epoch) 3 (batch) 80 (loss) 0.3849\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7605\n",
      "(epoch) 4 (batch) 0 (loss) 0.4061\n",
      "(epoch) 4 (batch) 16 (loss) 0.4018\n",
      "(epoch) 4 (batch) 32 (loss) 0.3668\n",
      "(epoch) 4 (batch) 48 (loss) 0.4055\n",
      "(epoch) 4 (batch) 64 (loss) 0.3632\n",
      "(epoch) 4 (batch) 80 (loss) 0.3730\n",
      "Epoch 004 | Validation score: 0.8274 | Test score: 0.8308\n",
      "(epoch) 5 (batch) 0 (loss) 0.3906\n",
      "(epoch) 5 (batch) 16 (loss) 0.3976\n",
      "(epoch) 5 (batch) 32 (loss) 0.3717\n",
      "(epoch) 5 (batch) 48 (loss) 0.3856\n",
      "(epoch) 5 (batch) 64 (loss) 0.3609\n",
      "(epoch) 5 (batch) 80 (loss) 0.3636\n",
      "Epoch 005 | Validation score: 0.8282 | Test score: 0.8308\n",
      "(epoch) 6 (batch) 0 (loss) 0.4010\n",
      "(epoch) 6 (batch) 16 (loss) 0.4002\n",
      "(epoch) 6 (batch) 32 (loss) 0.3535\n",
      "(epoch) 6 (batch) 48 (loss) 0.4096\n",
      "(epoch) 6 (batch) 64 (loss) 0.3509\n",
      "(epoch) 6 (batch) 80 (loss) 0.3720\n",
      "Epoch 006 | Validation score: 0.8276 | Test score: 0.8311\n",
      "(epoch) 7 (batch) 0 (loss) 0.3841\n",
      "(epoch) 7 (batch) 16 (loss) 0.3921\n",
      "(epoch) 7 (batch) 32 (loss) 0.3591\n",
      "(epoch) 7 (batch) 48 (loss) 0.3864\n",
      "(epoch) 7 (batch) 64 (loss) 0.3323\n",
      "(epoch) 7 (batch) 80 (loss) 0.3663\n",
      "Epoch 007 | Validation score: 0.8286 | Test score: 0.8334\n",
      "(epoch) 8 (batch) 0 (loss) 0.4013\n",
      "(epoch) 8 (batch) 16 (loss) 0.3828\n",
      "(epoch) 8 (batch) 32 (loss) 0.3644\n",
      "(epoch) 8 (batch) 48 (loss) 0.3917\n",
      "(epoch) 8 (batch) 64 (loss) 0.3324\n",
      "(epoch) 8 (batch) 80 (loss) 0.3732\n",
      "Epoch 008 | Validation score: 0.8322 | Test score: 0.8348\n",
      "(epoch) 9 (batch) 0 (loss) 0.3912\n",
      "(epoch) 9 (batch) 16 (loss) 0.3894\n",
      "(epoch) 9 (batch) 32 (loss) 0.3557\n",
      "(epoch) 9 (batch) 48 (loss) 0.3992\n",
      "(epoch) 9 (batch) 64 (loss) 0.3418\n",
      "(epoch) 9 (batch) 80 (loss) 0.3599\n",
      "Epoch 009 | Validation score: 0.8311 | Test score: 0.8351\n",
      "(epoch) 10 (batch) 0 (loss) 0.3643\n",
      "(epoch) 10 (batch) 16 (loss) 0.3848\n",
      "(epoch) 10 (batch) 32 (loss) 0.3298\n",
      "(epoch) 10 (batch) 48 (loss) 0.3980\n",
      "(epoch) 10 (batch) 64 (loss) 0.3238\n",
      "(epoch) 10 (batch) 80 (loss) 0.3662\n",
      "Epoch 010 | Validation score: 0.8298 | Test score: 0.8351\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.6784\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.6562\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.6157\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.5899\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.5356\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.4768\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.4953\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.4535\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.4015\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.4525\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.3981\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4089\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4269\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4051\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3742\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4282\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3776\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.3969\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4144\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4080\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3839\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4336\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3527\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.3908\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4366\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4040\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3729\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4124\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3664\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3785\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4153\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.3882\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3648\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.4190\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3553\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3594\n",
      "Epoch 006 | Validation score: 0.8315 | Test score: 0.8345\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4033\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.4035\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3624\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 7 (relational-batch) 64 (loss) 0.3481\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3874\n",
      "Epoch 007 | Validation score: 0.8317 | Test score: 0.8340\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4097\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3822\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3655\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.4103\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3480\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3659\n",
      "Epoch 008 | Validation score: 0.8301 | Test score: 0.8326\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4198\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.3912\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3531\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.4181\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3578\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3950\n",
      "Epoch 009 | Validation score: 0.8319 | Test score: 0.8340\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4313\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.4166\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3698\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.4067\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3322\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3644\n",
      "Epoch 010 | Validation score: 0.8321 | Test score: 0.8346\n",
      "(epoch) 1 (batch) 0 (loss) 0.6216\n",
      "(epoch) 1 (batch) 16 (loss) 0.6075\n",
      "(epoch) 1 (batch) 32 (loss) 0.5686\n",
      "(epoch) 1 (batch) 48 (loss) 0.5694\n",
      "(epoch) 1 (batch) 64 (loss) 0.5057\n",
      "(epoch) 1 (batch) 80 (loss) 0.5015\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.4873\n",
      "(epoch) 2 (batch) 16 (loss) 0.4660\n",
      "(epoch) 2 (batch) 32 (loss) 0.4149\n",
      "(epoch) 2 (batch) 48 (loss) 0.4550\n",
      "(epoch) 2 (batch) 64 (loss) 0.3798\n",
      "(epoch) 2 (batch) 80 (loss) 0.4286\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4118\n",
      "(epoch) 3 (batch) 16 (loss) 0.4105\n",
      "(epoch) 3 (batch) 32 (loss) 0.3538\n",
      "(epoch) 3 (batch) 48 (loss) 0.4336\n",
      "(epoch) 3 (batch) 64 (loss) 0.3400\n",
      "(epoch) 3 (batch) 80 (loss) 0.4043\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4236\n",
      "(epoch) 4 (batch) 16 (loss) 0.4002\n",
      "(epoch) 4 (batch) 32 (loss) 0.3421\n",
      "(epoch) 4 (batch) 48 (loss) 0.4268\n",
      "(epoch) 4 (batch) 64 (loss) 0.3524\n",
      "(epoch) 4 (batch) 80 (loss) 0.4014\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4125\n",
      "(epoch) 5 (batch) 16 (loss) 0.4030\n",
      "(epoch) 5 (batch) 32 (loss) 0.3521\n",
      "(epoch) 5 (batch) 48 (loss) 0.4088\n",
      "(epoch) 5 (batch) 64 (loss) 0.3513\n",
      "(epoch) 5 (batch) 80 (loss) 0.3775\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (batch) 0 (loss) 0.4120\n",
      "(epoch) 6 (batch) 16 (loss) 0.3973\n",
      "(epoch) 6 (batch) 32 (loss) 0.3380\n",
      "(epoch) 6 (batch) 48 (loss) 0.3861\n",
      "(epoch) 6 (batch) 64 (loss) 0.3450\n",
      "(epoch) 6 (batch) 80 (loss) 0.3782\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (batch) 0 (loss) 0.4137\n",
      "(epoch) 7 (batch) 16 (loss) 0.3957\n",
      "(epoch) 7 (batch) 32 (loss) 0.3559\n",
      "(epoch) 7 (batch) 48 (loss) 0.3931\n",
      "(epoch) 7 (batch) 64 (loss) 0.3433\n",
      "(epoch) 7 (batch) 80 (loss) 0.3566\n",
      "Epoch 007 | Validation score: 0.8313 | Test score: 0.8319\n",
      "(epoch) 8 (batch) 0 (loss) 0.4032\n",
      "(epoch) 8 (batch) 16 (loss) 0.4032\n",
      "(epoch) 8 (batch) 32 (loss) 0.3517\n",
      "(epoch) 8 (batch) 48 (loss) 0.4042\n",
      "(epoch) 8 (batch) 64 (loss) 0.3556\n",
      "(epoch) 8 (batch) 80 (loss) 0.3639\n",
      "Epoch 008 | Validation score: 0.8340 | Test score: 0.8357\n",
      "(epoch) 9 (batch) 0 (loss) 0.4163\n",
      "(epoch) 9 (batch) 16 (loss) 0.3812\n",
      "(epoch) 9 (batch) 32 (loss) 0.3539\n",
      "(epoch) 9 (batch) 48 (loss) 0.3866\n",
      "(epoch) 9 (batch) 64 (loss) 0.3514\n",
      "(epoch) 9 (batch) 80 (loss) 0.3759\n",
      "Epoch 009 | Validation score: 0.8326 | Test score: 0.8354\n",
      "(epoch) 10 (batch) 0 (loss) 0.4151\n",
      "(epoch) 10 (batch) 16 (loss) 0.4069\n",
      "(epoch) 10 (batch) 32 (loss) 0.3546\n",
      "(epoch) 10 (batch) 48 (loss) 0.4043\n",
      "(epoch) 10 (batch) 64 (loss) 0.3365\n",
      "(epoch) 10 (batch) 80 (loss) 0.3648\n",
      "Epoch 010 | Validation score: 0.8321 | Test score: 0.8362\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.7662\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7512\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.7436\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.7171\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.6940\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.6359\n",
      "Epoch 001 | Validation score: 0.7965 | Test score: 0.7947\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.6358\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.5725\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.4868\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.4791\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4074\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4156\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4313\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.3993\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3869\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4361\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3665\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4193\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4197\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4075\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3715\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4149\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3599\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4112\n",
      "Epoch 004 | Validation score: 0.8328 | Test score: 0.8348\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4155\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4126\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3608\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4088\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3441\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3768\n",
      "Epoch 005 | Validation score: 0.8322 | Test score: 0.8334\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.3973\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4130\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3517\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.4081\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3482\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3753\n",
      "Epoch 006 | Validation score: 0.8319 | Test score: 0.8362\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.3937\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3922\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3378\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3948\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3534\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3800\n",
      "Epoch 007 | Validation score: 0.8324 | Test score: 0.8368\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4063\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.4023\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3474\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.4100\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3415\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3786\n",
      "Epoch 008 | Validation score: 0.8336 | Test score: 0.8379\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4018\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4008\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3667\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3944\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3443\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3774\n",
      "Epoch 009 | Validation score: 0.8334 | Test score: 0.8396\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4101\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3951\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3567\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.4018\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3518\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3899\n",
      "Epoch 010 | Validation score: 0.8340 | Test score: 0.8399\n",
      "(epoch) 1 (batch) 0 (loss) 0.9353\n",
      "(epoch) 1 (batch) 16 (loss) 0.9009\n",
      "(epoch) 1 (batch) 32 (loss) 0.8910\n",
      "(epoch) 1 (batch) 48 (loss) 0.8307\n",
      "(epoch) 1 (batch) 64 (loss) 0.8084\n",
      "(epoch) 1 (batch) 80 (loss) 0.7380\n",
      "Epoch 001 | Validation score: 0.3862 | Test score: 0.3814\n",
      "(epoch) 2 (batch) 0 (loss) 0.7300\n",
      "(epoch) 2 (batch) 16 (loss) 0.6500\n",
      "(epoch) 2 (batch) 32 (loss) 0.5850\n",
      "(epoch) 2 (batch) 48 (loss) 0.5188\n",
      "(epoch) 2 (batch) 64 (loss) 0.4325\n",
      "(epoch) 2 (batch) 80 (loss) 0.4554\n",
      "Epoch 002 | Validation score: 0.8163 | Test score: 0.8242\n",
      "(epoch) 3 (batch) 0 (loss) 0.4618\n",
      "(epoch) 3 (batch) 16 (loss) 0.4284\n",
      "(epoch) 3 (batch) 32 (loss) 0.3651\n",
      "(epoch) 3 (batch) 48 (loss) 0.4427\n",
      "(epoch) 3 (batch) 64 (loss) 0.3690\n",
      "(epoch) 3 (batch) 80 (loss) 0.4169\n",
      "Epoch 003 | Validation score: 0.8319 | Test score: 0.8382\n",
      "(epoch) 4 (batch) 0 (loss) 0.4283\n",
      "(epoch) 4 (batch) 16 (loss) 0.4054\n",
      "(epoch) 4 (batch) 32 (loss) 0.3483\n",
      "(epoch) 4 (batch) 48 (loss) 0.4518\n",
      "(epoch) 4 (batch) 64 (loss) 0.3500\n",
      "(epoch) 4 (batch) 80 (loss) 0.4201\n",
      "Epoch 004 | Validation score: 0.8330 | Test score: 0.8391\n",
      "(epoch) 5 (batch) 0 (loss) 0.4094\n",
      "(epoch) 5 (batch) 16 (loss) 0.3927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 5 (batch) 32 (loss) 0.3364\n",
      "(epoch) 5 (batch) 48 (loss) 0.4151\n",
      "(epoch) 5 (batch) 64 (loss) 0.3484\n",
      "(epoch) 5 (batch) 80 (loss) 0.3912\n",
      "Epoch 005 | Validation score: 0.8332 | Test score: 0.8386\n",
      "(epoch) 6 (batch) 0 (loss) 0.4059\n",
      "(epoch) 6 (batch) 16 (loss) 0.3920\n",
      "(epoch) 6 (batch) 32 (loss) 0.3500\n",
      "(epoch) 6 (batch) 48 (loss) 0.4053\n",
      "(epoch) 6 (batch) 64 (loss) 0.3457\n",
      "(epoch) 6 (batch) 80 (loss) 0.3832\n",
      "Epoch 006 | Validation score: 0.8338 | Test score: 0.8400\n",
      "(epoch) 7 (batch) 0 (loss) 0.4118\n",
      "(epoch) 7 (batch) 16 (loss) 0.4193\n",
      "(epoch) 7 (batch) 32 (loss) 0.3571\n",
      "(epoch) 7 (batch) 48 (loss) 0.4060\n",
      "(epoch) 7 (batch) 64 (loss) 0.3597\n",
      "(epoch) 7 (batch) 80 (loss) 0.3859\n",
      "Epoch 007 | Validation score: 0.8345 | Test score: 0.8392\n",
      "(epoch) 8 (batch) 0 (loss) 0.4211\n",
      "(epoch) 8 (batch) 16 (loss) 0.3913\n",
      "(epoch) 8 (batch) 32 (loss) 0.3272\n",
      "(epoch) 8 (batch) 48 (loss) 0.4138\n",
      "(epoch) 8 (batch) 64 (loss) 0.3553\n",
      "(epoch) 8 (batch) 80 (loss) 0.3578\n",
      "Epoch 008 | Validation score: 0.8336 | Test score: 0.8394\n",
      "(epoch) 9 (batch) 0 (loss) 0.4139\n",
      "(epoch) 9 (batch) 16 (loss) 0.3818\n",
      "(epoch) 9 (batch) 32 (loss) 0.3635\n",
      "(epoch) 9 (batch) 48 (loss) 0.3906\n",
      "(epoch) 9 (batch) 64 (loss) 0.3357\n",
      "(epoch) 9 (batch) 80 (loss) 0.3609\n",
      "Epoch 009 | Validation score: 0.8326 | Test score: 0.8382\n",
      "(epoch) 10 (batch) 0 (loss) 0.4149\n",
      "(epoch) 10 (batch) 16 (loss) 0.3992\n",
      "(epoch) 10 (batch) 32 (loss) 0.3427\n",
      "(epoch) 10 (batch) 48 (loss) 0.3970\n",
      "(epoch) 10 (batch) 64 (loss) 0.3408\n",
      "(epoch) 10 (batch) 80 (loss) 0.3679\n",
      "Epoch 010 | Validation score: 0.8340 | Test score: 0.8388\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.8216\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7835\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.7392\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.6876\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.6311\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.5669\n",
      "Epoch 001 | Validation score: 0.7942 | Test score: 0.8010\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.5722\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.4980\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.4621\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.4630\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4251\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4420\n",
      "Epoch 002 | Validation score: 0.8228 | Test score: 0.8299\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4401\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4437\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3911\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4307\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.4036\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4282\n",
      "Epoch 003 | Validation score: 0.8313 | Test score: 0.8371\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4564\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4244\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3668\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4107\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3868\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.3803\n",
      "Epoch 004 | Validation score: 0.8311 | Test score: 0.8376\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4174\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4102\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3810\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4073\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3682\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.4297\n",
      "Epoch 005 | Validation score: 0.8296 | Test score: 0.8389\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4472\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4210\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3548\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3976\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3684\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3915\n",
      "Epoch 006 | Validation score: 0.8322 | Test score: 0.8388\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4272\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3965\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3509\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.4109\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3697\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3978\n",
      "Epoch 007 | Validation score: 0.8355 | Test score: 0.8379 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4254\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.4241\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3640\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3908\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3641\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3915\n",
      "Epoch 008 | Validation score: 0.8332 | Test score: 0.8396\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4122\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4046\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3554\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.4092\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3445\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.4080\n",
      "Epoch 009 | Validation score: 0.8324 | Test score: 0.8409\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4259\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.4076\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3452\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3897\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3577\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3730\n",
      "Epoch 010 | Validation score: 0.8324 | Test score: 0.8394\n",
      "(epoch) 1 (batch) 0 (loss) 0.6063\n",
      "(epoch) 1 (batch) 16 (loss) 0.5886\n",
      "(epoch) 1 (batch) 32 (loss) 0.5449\n",
      "(epoch) 1 (batch) 48 (loss) 0.5533\n",
      "(epoch) 1 (batch) 64 (loss) 0.4947\n",
      "(epoch) 1 (batch) 80 (loss) 0.4805\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.4776\n",
      "(epoch) 2 (batch) 16 (loss) 0.4661\n",
      "(epoch) 2 (batch) 32 (loss) 0.4007\n",
      "(epoch) 2 (batch) 48 (loss) 0.4504\n",
      "(epoch) 2 (batch) 64 (loss) 0.3797\n",
      "(epoch) 2 (batch) 80 (loss) 0.4004\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4407\n",
      "(epoch) 3 (batch) 16 (loss) 0.4115\n",
      "(epoch) 3 (batch) 32 (loss) 0.3731\n",
      "(epoch) 3 (batch) 48 (loss) 0.4311\n",
      "(epoch) 3 (batch) 64 (loss) 0.3735\n",
      "(epoch) 3 (batch) 80 (loss) 0.4013\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4057\n",
      "(epoch) 4 (batch) 16 (loss) 0.4038\n",
      "(epoch) 4 (batch) 32 (loss) 0.3489\n",
      "(epoch) 4 (batch) 48 (loss) 0.4180\n",
      "(epoch) 4 (batch) 64 (loss) 0.3519\n",
      "(epoch) 4 (batch) 80 (loss) 0.3666\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4041\n",
      "(epoch) 5 (batch) 16 (loss) 0.4046\n",
      "(epoch) 5 (batch) 32 (loss) 0.3620\n",
      "(epoch) 5 (batch) 48 (loss) 0.4037\n",
      "(epoch) 5 (batch) 64 (loss) 0.3538\n",
      "(epoch) 5 (batch) 80 (loss) 0.3722\n",
      "Epoch 005 | Validation score: 0.8347 | Test score: 0.8320\n",
      "(epoch) 6 (batch) 0 (loss) 0.3963\n",
      "(epoch) 6 (batch) 16 (loss) 0.3802\n",
      "(epoch) 6 (batch) 32 (loss) 0.3392\n",
      "(epoch) 6 (batch) 48 (loss) 0.4114\n",
      "(epoch) 6 (batch) 64 (loss) 0.3463\n",
      "(epoch) 6 (batch) 80 (loss) 0.3658\n",
      "Epoch 006 | Validation score: 0.8326 | Test score: 0.8325\n",
      "(epoch) 7 (batch) 0 (loss) 0.3998\n",
      "(epoch) 7 (batch) 16 (loss) 0.3783\n",
      "(epoch) 7 (batch) 32 (loss) 0.3332\n",
      "(epoch) 7 (batch) 48 (loss) 0.4226\n",
      "(epoch) 7 (batch) 64 (loss) 0.3457\n",
      "(epoch) 7 (batch) 80 (loss) 0.3712\n",
      "Epoch 007 | Validation score: 0.8303 | Test score: 0.8337\n",
      "(epoch) 8 (batch) 0 (loss) 0.4071\n",
      "(epoch) 8 (batch) 16 (loss) 0.4113\n",
      "(epoch) 8 (batch) 32 (loss) 0.3674\n",
      "(epoch) 8 (batch) 48 (loss) 0.3779\n",
      "(epoch) 8 (batch) 64 (loss) 0.3536\n",
      "(epoch) 8 (batch) 80 (loss) 0.3803\n",
      "Epoch 008 | Validation score: 0.8326 | Test score: 0.8356\n",
      "(epoch) 9 (batch) 0 (loss) 0.3975\n",
      "(epoch) 9 (batch) 16 (loss) 0.3887\n",
      "(epoch) 9 (batch) 32 (loss) 0.3389\n",
      "(epoch) 9 (batch) 48 (loss) 0.4105\n",
      "(epoch) 9 (batch) 64 (loss) 0.3578\n",
      "(epoch) 9 (batch) 80 (loss) 0.3676\n",
      "Epoch 009 | Validation score: 0.8326 | Test score: 0.8340\n",
      "(epoch) 10 (batch) 0 (loss) 0.3883\n",
      "(epoch) 10 (batch) 16 (loss) 0.3874\n",
      "(epoch) 10 (batch) 32 (loss) 0.3482\n",
      "(epoch) 10 (batch) 48 (loss) 0.3780\n",
      "(epoch) 10 (batch) 64 (loss) 0.3545\n",
      "(epoch) 10 (batch) 80 (loss) 0.3625\n",
      "Epoch 010 | Validation score: 0.8332 | Test score: 0.8345\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.8289\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7935\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.7762\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.7291\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.6954\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.6556\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.6478\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.6018\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.5394\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.5353\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4642\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4612\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 3 (relational-batch) 16 (loss) 0.4605\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3998\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4459\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3979\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4207\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4358\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4169\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.4076\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4451\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3685\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.3932\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.3957\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4077\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3888\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4371\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3664\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.4323\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4137\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4067\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3600\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.4324\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3733\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3892\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4159\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3981\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3773\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.4085\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3573\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3807\n",
      "Epoch 007 | Validation score: 0.8236 | Test score: 0.8280\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.3879\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3869\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3722\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.4087\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3421\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3773\n",
      "Epoch 008 | Validation score: 0.8257 | Test score: 0.8287\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.3991\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4092\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3535\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.4063\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3671\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3937\n",
      "Epoch 009 | Validation score: 0.8238 | Test score: 0.8274\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4260\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3939\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3521\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.4094\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3542\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3892\n",
      "Epoch 010 | Validation score: 0.8255 | Test score: 0.8285\n",
      "(epoch) 1 (batch) 0 (loss) 0.7202\n",
      "(epoch) 1 (batch) 16 (loss) 0.6994\n",
      "(epoch) 1 (batch) 32 (loss) 0.6731\n",
      "(epoch) 1 (batch) 48 (loss) 0.6417\n",
      "(epoch) 1 (batch) 64 (loss) 0.5888\n",
      "(epoch) 1 (batch) 80 (loss) 0.5526\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.5564\n",
      "(epoch) 2 (batch) 16 (loss) 0.5223\n",
      "(epoch) 2 (batch) 32 (loss) 0.4710\n",
      "(epoch) 2 (batch) 48 (loss) 0.4756\n",
      "(epoch) 2 (batch) 64 (loss) 0.4154\n",
      "(epoch) 2 (batch) 80 (loss) 0.3999\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4458\n",
      "(epoch) 3 (batch) 16 (loss) 0.4149\n",
      "(epoch) 3 (batch) 32 (loss) 0.3909\n",
      "(epoch) 3 (batch) 48 (loss) 0.4425\n",
      "(epoch) 3 (batch) 64 (loss) 0.3670\n",
      "(epoch) 3 (batch) 80 (loss) 0.3945\n",
      "Epoch 003 | Validation score: 0.7618 | Test score: 0.7746\n",
      "(epoch) 4 (batch) 0 (loss) 0.4439\n",
      "(epoch) 4 (batch) 16 (loss) 0.4132\n",
      "(epoch) 4 (batch) 32 (loss) 0.3854\n",
      "(epoch) 4 (batch) 48 (loss) 0.4351\n",
      "(epoch) 4 (batch) 64 (loss) 0.3524\n",
      "(epoch) 4 (batch) 80 (loss) 0.3863\n",
      "Epoch 004 | Validation score: 0.8344 | Test score: 0.8391\n",
      "(epoch) 5 (batch) 0 (loss) 0.4391\n",
      "(epoch) 5 (batch) 16 (loss) 0.4087\n",
      "(epoch) 5 (batch) 32 (loss) 0.3594\n",
      "(epoch) 5 (batch) 48 (loss) 0.4174\n",
      "(epoch) 5 (batch) 64 (loss) 0.3458\n",
      "(epoch) 5 (batch) 80 (loss) 0.3877\n",
      "Epoch 005 | Validation score: 0.8321 | Test score: 0.8369\n",
      "(epoch) 6 (batch) 0 (loss) 0.4436\n",
      "(epoch) 6 (batch) 16 (loss) 0.4130\n",
      "(epoch) 6 (batch) 32 (loss) 0.3353\n",
      "(epoch) 6 (batch) 48 (loss) 0.3960\n",
      "(epoch) 6 (batch) 64 (loss) 0.3381\n",
      "(epoch) 6 (batch) 80 (loss) 0.3573\n",
      "Epoch 006 | Validation score: 0.8340 | Test score: 0.8359\n",
      "(epoch) 7 (batch) 0 (loss) 0.4158\n",
      "(epoch) 7 (batch) 16 (loss) 0.3791\n",
      "(epoch) 7 (batch) 32 (loss) 0.3478\n",
      "(epoch) 7 (batch) 48 (loss) 0.3987\n",
      "(epoch) 7 (batch) 64 (loss) 0.3500\n",
      "(epoch) 7 (batch) 80 (loss) 0.3486\n",
      "Epoch 007 | Validation score: 0.8361 | Test score: 0.8369 <<< BEST VALIDATION EPOCH\n",
      "(epoch) 8 (batch) 0 (loss) 0.3967\n",
      "(epoch) 8 (batch) 16 (loss) 0.4011\n",
      "(epoch) 8 (batch) 32 (loss) 0.3457\n",
      "(epoch) 8 (batch) 48 (loss) 0.3956\n",
      "(epoch) 8 (batch) 64 (loss) 0.3421\n",
      "(epoch) 8 (batch) 80 (loss) 0.3672\n",
      "Epoch 008 | Validation score: 0.8351 | Test score: 0.8385\n",
      "(epoch) 9 (batch) 0 (loss) 0.4163\n",
      "(epoch) 9 (batch) 16 (loss) 0.3935\n",
      "(epoch) 9 (batch) 32 (loss) 0.3471\n",
      "(epoch) 9 (batch) 48 (loss) 0.3916\n",
      "(epoch) 9 (batch) 64 (loss) 0.3589\n",
      "(epoch) 9 (batch) 80 (loss) 0.3835\n",
      "Epoch 009 | Validation score: 0.8345 | Test score: 0.8376\n",
      "(epoch) 10 (batch) 0 (loss) 0.3818\n",
      "(epoch) 10 (batch) 16 (loss) 0.3695\n",
      "(epoch) 10 (batch) 32 (loss) 0.3493\n",
      "(epoch) 10 (batch) 48 (loss) 0.3893\n",
      "(epoch) 10 (batch) 64 (loss) 0.3409\n",
      "(epoch) 10 (batch) 80 (loss) 0.3531\n",
      "Epoch 010 | Validation score: 0.8347 | Test score: 0.8376\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.8152\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7896\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.7756\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.7456\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.7371\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.7112\n",
      "Epoch 001 | Validation score: 0.2574 | Test score: 0.2501\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.7118\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.6841\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.6516\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.6104\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.5704\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.5174\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.5047\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4602\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.4118\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4349\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3811\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4125\n",
      "Epoch 003 | Validation score: 0.7620 | Test score: 0.7725\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4213\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4284\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3720\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.3977\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3443\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.3780\n",
      "Epoch 004 | Validation score: 0.8340 | Test score: 0.8351\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4478\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.3961\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3578\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.3856\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3453\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3866\n",
      "Epoch 005 | Validation score: 0.8336 | Test score: 0.8363\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4029\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.3995\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3480\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3842\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3544\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3647\n",
      "Epoch 006 | Validation score: 0.8344 | Test score: 0.8357\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4322\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3939\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3264\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3728\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3457\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3526\n",
      "Epoch 007 | Validation score: 0.8340 | Test score: 0.8357\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4193\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3871\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3467\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3867\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3262\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3594\n",
      "Epoch 008 | Validation score: 0.8351 | Test score: 0.8372\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4282\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4177\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3324\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3707\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 9 (relational-batch) 80 (loss) 0.3332\n",
      "Epoch 009 | Validation score: 0.8347 | Test score: 0.8372\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4129\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3943\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3501\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3938\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3298\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3456\n",
      "Epoch 010 | Validation score: 0.8326 | Test score: 0.8371\n",
      "(epoch) 1 (batch) 0 (loss) 0.6201\n",
      "(epoch) 1 (batch) 16 (loss) 0.5913\n",
      "(epoch) 1 (batch) 32 (loss) 0.5479\n",
      "(epoch) 1 (batch) 48 (loss) 0.5570\n",
      "(epoch) 1 (batch) 64 (loss) 0.4970\n",
      "(epoch) 1 (batch) 80 (loss) 0.4979\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.4856\n",
      "(epoch) 2 (batch) 16 (loss) 0.4620\n",
      "(epoch) 2 (batch) 32 (loss) 0.4037\n",
      "(epoch) 2 (batch) 48 (loss) 0.4537\n",
      "(epoch) 2 (batch) 64 (loss) 0.3960\n",
      "(epoch) 2 (batch) 80 (loss) 0.4587\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4311\n",
      "(epoch) 3 (batch) 16 (loss) 0.4105\n",
      "(epoch) 3 (batch) 32 (loss) 0.3614\n",
      "(epoch) 3 (batch) 48 (loss) 0.4152\n",
      "(epoch) 3 (batch) 64 (loss) 0.3728\n",
      "(epoch) 3 (batch) 80 (loss) 0.4028\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4043\n",
      "(epoch) 4 (batch) 16 (loss) 0.4019\n",
      "(epoch) 4 (batch) 32 (loss) 0.3471\n",
      "(epoch) 4 (batch) 48 (loss) 0.4066\n",
      "(epoch) 4 (batch) 64 (loss) 0.3441\n",
      "(epoch) 4 (batch) 80 (loss) 0.3847\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4045\n",
      "(epoch) 5 (batch) 16 (loss) 0.4005\n",
      "(epoch) 5 (batch) 32 (loss) 0.3653\n",
      "(epoch) 5 (batch) 48 (loss) 0.4137\n",
      "(epoch) 5 (batch) 64 (loss) 0.3357\n",
      "(epoch) 5 (batch) 80 (loss) 0.3974\n",
      "Epoch 005 | Validation score: 0.8259 | Test score: 0.8322\n",
      "(epoch) 6 (batch) 0 (loss) 0.4044\n",
      "(epoch) 6 (batch) 16 (loss) 0.3998\n",
      "(epoch) 6 (batch) 32 (loss) 0.3477\n",
      "(epoch) 6 (batch) 48 (loss) 0.4071\n",
      "(epoch) 6 (batch) 64 (loss) 0.3377\n",
      "(epoch) 6 (batch) 80 (loss) 0.3900\n",
      "Epoch 006 | Validation score: 0.8278 | Test score: 0.8334\n",
      "(epoch) 7 (batch) 0 (loss) 0.4073\n",
      "(epoch) 7 (batch) 16 (loss) 0.3895\n",
      "(epoch) 7 (batch) 32 (loss) 0.3594\n",
      "(epoch) 7 (batch) 48 (loss) 0.3994\n",
      "(epoch) 7 (batch) 64 (loss) 0.3395\n",
      "(epoch) 7 (batch) 80 (loss) 0.4020\n",
      "Epoch 007 | Validation score: 0.8276 | Test score: 0.8342\n",
      "(epoch) 8 (batch) 0 (loss) 0.4079\n",
      "(epoch) 8 (batch) 16 (loss) 0.3871\n",
      "(epoch) 8 (batch) 32 (loss) 0.3310\n",
      "(epoch) 8 (batch) 48 (loss) 0.4143\n",
      "(epoch) 8 (batch) 64 (loss) 0.3501\n",
      "(epoch) 8 (batch) 80 (loss) 0.3908\n",
      "Epoch 008 | Validation score: 0.8284 | Test score: 0.8334\n",
      "(epoch) 9 (batch) 0 (loss) 0.4240\n",
      "(epoch) 9 (batch) 16 (loss) 0.4030\n",
      "(epoch) 9 (batch) 32 (loss) 0.3271\n",
      "(epoch) 9 (batch) 48 (loss) 0.3893\n",
      "(epoch) 9 (batch) 64 (loss) 0.3404\n",
      "(epoch) 9 (batch) 80 (loss) 0.3640\n",
      "Epoch 009 | Validation score: 0.8292 | Test score: 0.8331\n",
      "(epoch) 10 (batch) 0 (loss) 0.4043\n",
      "(epoch) 10 (batch) 16 (loss) 0.4039\n",
      "(epoch) 10 (batch) 32 (loss) 0.3369\n",
      "(epoch) 10 (batch) 48 (loss) 0.3885\n",
      "(epoch) 10 (batch) 64 (loss) 0.3199\n",
      "(epoch) 10 (batch) 80 (loss) 0.3959\n",
      "Epoch 010 | Validation score: 0.8322 | Test score: 0.8357\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.8283\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.7973\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.7860\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.7566\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.7486\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.7193\n",
      "Epoch 001 | Validation score: 0.2518 | Test score: 0.2421\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.7203\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.6813\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.6144\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.5473\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4622\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4659\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4479\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4522\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.4008\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4504\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3906\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4130\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4260\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4096\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3708\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4164\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3850\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4145\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4092\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4207\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3630\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4205\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3701\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3944\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4072\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4087\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3638\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.4047\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3646\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.4103\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4124\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3929\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3560\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3885\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3550\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3977\n",
      "Epoch 007 | Validation score: 0.8282 | Test score: 0.8339\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4171\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.4285\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3421\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.4202\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3501\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3796\n",
      "Epoch 008 | Validation score: 0.8259 | Test score: 0.8317\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4058\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4122\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3373\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.4077\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3473\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3618\n",
      "Epoch 009 | Validation score: 0.8255 | Test score: 0.8310\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4241\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.4169\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3546\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3741\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3560\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3695\n",
      "Epoch 010 | Validation score: 0.8255 | Test score: 0.8325\n",
      "(epoch) 1 (batch) 0 (loss) 0.5315\n",
      "(epoch) 1 (batch) 16 (loss) 0.5379\n",
      "(epoch) 1 (batch) 32 (loss) 0.4931\n",
      "(epoch) 1 (batch) 48 (loss) 0.5336\n",
      "(epoch) 1 (batch) 64 (loss) 0.4730\n",
      "(epoch) 1 (batch) 80 (loss) 0.5003\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.4836\n",
      "(epoch) 2 (batch) 16 (loss) 0.4836\n",
      "(epoch) 2 (batch) 32 (loss) 0.4123\n",
      "(epoch) 2 (batch) 48 (loss) 0.4570\n",
      "(epoch) 2 (batch) 64 (loss) 0.4005\n",
      "(epoch) 2 (batch) 80 (loss) 0.4313\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4220\n",
      "(epoch) 3 (batch) 16 (loss) 0.4199\n",
      "(epoch) 3 (batch) 32 (loss) 0.3728\n",
      "(epoch) 3 (batch) 48 (loss) 0.4183\n",
      "(epoch) 3 (batch) 64 (loss) 0.3573\n",
      "(epoch) 3 (batch) 80 (loss) 0.4096\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4256\n",
      "(epoch) 4 (batch) 16 (loss) 0.4086\n",
      "(epoch) 4 (batch) 32 (loss) 0.3672\n",
      "(epoch) 4 (batch) 48 (loss) 0.4042\n",
      "(epoch) 4 (batch) 64 (loss) 0.3603\n",
      "(epoch) 4 (batch) 80 (loss) 0.3964\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4025\n",
      "(epoch) 5 (batch) 16 (loss) 0.4021\n",
      "(epoch) 5 (batch) 32 (loss) 0.3614\n",
      "(epoch) 5 (batch) 48 (loss) 0.4064\n",
      "(epoch) 5 (batch) 64 (loss) 0.3525\n",
      "(epoch) 5 (batch) 80 (loss) 0.3970\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (batch) 0 (loss) 0.4116\n",
      "(epoch) 6 (batch) 16 (loss) 0.4093\n",
      "(epoch) 6 (batch) 32 (loss) 0.3528\n",
      "(epoch) 6 (batch) 48 (loss) 0.3992\n",
      "(epoch) 6 (batch) 64 (loss) 0.3538\n",
      "(epoch) 6 (batch) 80 (loss) 0.3881\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (batch) 0 (loss) 0.4003\n",
      "(epoch) 7 (batch) 16 (loss) 0.3952\n",
      "(epoch) 7 (batch) 32 (loss) 0.3477\n",
      "(epoch) 7 (batch) 48 (loss) 0.3894\n",
      "(epoch) 7 (batch) 64 (loss) 0.3563\n",
      "(epoch) 7 (batch) 80 (loss) 0.3736\n",
      "Epoch 007 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 8 (batch) 0 (loss) 0.4105\n",
      "(epoch) 8 (batch) 16 (loss) 0.4038\n",
      "(epoch) 8 (batch) 32 (loss) 0.3521\n",
      "(epoch) 8 (batch) 48 (loss) 0.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 8 (batch) 64 (loss) 0.3501\n",
      "(epoch) 8 (batch) 80 (loss) 0.3801\n",
      "Epoch 008 | Validation score: 0.8324 | Test score: 0.8333\n",
      "(epoch) 9 (batch) 0 (loss) 0.3970\n",
      "(epoch) 9 (batch) 16 (loss) 0.3881\n",
      "(epoch) 9 (batch) 32 (loss) 0.3511\n",
      "(epoch) 9 (batch) 48 (loss) 0.3755\n",
      "(epoch) 9 (batch) 64 (loss) 0.3365\n",
      "(epoch) 9 (batch) 80 (loss) 0.3759\n",
      "Epoch 009 | Validation score: 0.8309 | Test score: 0.8333\n",
      "(epoch) 10 (batch) 0 (loss) 0.3942\n",
      "(epoch) 10 (batch) 16 (loss) 0.3869\n",
      "(epoch) 10 (batch) 32 (loss) 0.3519\n",
      "(epoch) 10 (batch) 48 (loss) 0.3825\n",
      "(epoch) 10 (batch) 64 (loss) 0.3535\n",
      "(epoch) 10 (batch) 80 (loss) 0.3787\n",
      "Epoch 010 | Validation score: 0.8322 | Test score: 0.8342\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.5700\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.5637\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.5304\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.5609\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.5164\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.5388\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.5249\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.5293\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.4842\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.5162\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.4559\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4650\n",
      "Epoch 002 | Validation score: 0.8035 | Test score: 0.8067\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4824\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4533\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3791\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4501\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3771\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4043\n",
      "Epoch 003 | Validation score: 0.8305 | Test score: 0.8337\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4648\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4160\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3547\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.3988\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3825\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4122\n",
      "Epoch 004 | Validation score: 0.8330 | Test score: 0.8366\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4283\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.3998\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3476\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4007\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3570\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.4168\n",
      "Epoch 005 | Validation score: 0.8353 | Test score: 0.8366\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4242\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.3898\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3433\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3942\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3664\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3819\n",
      "Epoch 006 | Validation score: 0.8340 | Test score: 0.8369\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4155\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3939\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3585\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3804\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3485\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3856\n",
      "Epoch 007 | Validation score: 0.8338 | Test score: 0.8383\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4404\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.4046\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3485\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3850\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3318\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3934\n",
      "Epoch 008 | Validation score: 0.8340 | Test score: 0.8385\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4038\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4043\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3374\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3682\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3649\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3987\n",
      "Epoch 009 | Validation score: 0.8344 | Test score: 0.8371\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4126\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3887\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3255\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3803\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3398\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3825\n",
      "Epoch 010 | Validation score: 0.8344 | Test score: 0.8356\n",
      "(epoch) 1 (batch) 0 (loss) 0.5388\n",
      "(epoch) 1 (batch) 16 (loss) 0.5454\n",
      "(epoch) 1 (batch) 32 (loss) 0.5134\n",
      "(epoch) 1 (batch) 48 (loss) 0.5526\n",
      "(epoch) 1 (batch) 64 (loss) 0.4948\n",
      "(epoch) 1 (batch) 80 (loss) 0.5139\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.4905\n",
      "(epoch) 2 (batch) 16 (loss) 0.4706\n",
      "(epoch) 2 (batch) 32 (loss) 0.4082\n",
      "(epoch) 2 (batch) 48 (loss) 0.4828\n",
      "(epoch) 2 (batch) 64 (loss) 0.3933\n",
      "(epoch) 2 (batch) 80 (loss) 0.4349\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4106\n",
      "(epoch) 3 (batch) 16 (loss) 0.4145\n",
      "(epoch) 3 (batch) 32 (loss) 0.3791\n",
      "(epoch) 3 (batch) 48 (loss) 0.4543\n",
      "(epoch) 3 (batch) 64 (loss) 0.3777\n",
      "(epoch) 3 (batch) 80 (loss) 0.4097\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4373\n",
      "(epoch) 4 (batch) 16 (loss) 0.4022\n",
      "(epoch) 4 (batch) 32 (loss) 0.3732\n",
      "(epoch) 4 (batch) 48 (loss) 0.4258\n",
      "(epoch) 4 (batch) 64 (loss) 0.3529\n",
      "(epoch) 4 (batch) 80 (loss) 0.3878\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4188\n",
      "(epoch) 5 (batch) 16 (loss) 0.4136\n",
      "(epoch) 5 (batch) 32 (loss) 0.3778\n",
      "(epoch) 5 (batch) 48 (loss) 0.4226\n",
      "(epoch) 5 (batch) 64 (loss) 0.3658\n",
      "(epoch) 5 (batch) 80 (loss) 0.3810\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (batch) 0 (loss) 0.4136\n",
      "(epoch) 6 (batch) 16 (loss) 0.3867\n",
      "(epoch) 6 (batch) 32 (loss) 0.3694\n",
      "(epoch) 6 (batch) 48 (loss) 0.4295\n",
      "(epoch) 6 (batch) 64 (loss) 0.3598\n",
      "(epoch) 6 (batch) 80 (loss) 0.3877\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (batch) 0 (loss) 0.4011\n",
      "(epoch) 7 (batch) 16 (loss) 0.3988\n",
      "(epoch) 7 (batch) 32 (loss) 0.3635\n",
      "(epoch) 7 (batch) 48 (loss) 0.4248\n",
      "(epoch) 7 (batch) 64 (loss) 0.3442\n",
      "(epoch) 7 (batch) 80 (loss) 0.4026\n",
      "Epoch 007 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 8 (batch) 0 (loss) 0.4173\n",
      "(epoch) 8 (batch) 16 (loss) 0.4008\n",
      "(epoch) 8 (batch) 32 (loss) 0.3491\n",
      "(epoch) 8 (batch) 48 (loss) 0.4268\n",
      "(epoch) 8 (batch) 64 (loss) 0.3603\n",
      "(epoch) 8 (batch) 80 (loss) 0.3699\n",
      "Epoch 008 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 9 (batch) 0 (loss) 0.4133\n",
      "(epoch) 9 (batch) 16 (loss) 0.3976\n",
      "(epoch) 9 (batch) 32 (loss) 0.3777\n",
      "(epoch) 9 (batch) 48 (loss) 0.3986\n",
      "(epoch) 9 (batch) 64 (loss) 0.3543\n",
      "(epoch) 9 (batch) 80 (loss) 0.3879\n",
      "Epoch 009 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 10 (batch) 0 (loss) 0.3921\n",
      "(epoch) 10 (batch) 16 (loss) 0.3865\n",
      "(epoch) 10 (batch) 32 (loss) 0.3682\n",
      "(epoch) 10 (batch) 48 (loss) 0.4144\n",
      "(epoch) 10 (batch) 64 (loss) 0.3463\n",
      "(epoch) 10 (batch) 80 (loss) 0.3738\n",
      "Epoch 010 | Validation score: 0.8292 | Test score: 0.8317\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.6628\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.6555\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.6414\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.6439\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.6253\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.6273\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.6224\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.6156\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.5801\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.5479\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.5071\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4896\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4853\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4584\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.4107\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4542\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.4227\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4461\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4617\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4338\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3905\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.4319\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3748\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4211\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4201\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4280\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3590\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 5 (relational-batch) 64 (loss) 0.3537\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3857\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4463\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.4070\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3444\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3968\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3614\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3843\n",
      "Epoch 006 | Validation score: 0.8244 | Test score: 0.8302\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4145\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.4081\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3576\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3864\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3554\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3823\n",
      "Epoch 007 | Validation score: 0.8253 | Test score: 0.8316\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.4196\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.4242\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3550\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.4070\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3539\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3567\n",
      "Epoch 008 | Validation score: 0.8286 | Test score: 0.8345\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4238\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.4130\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3578\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3876\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3334\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3702\n",
      "Epoch 009 | Validation score: 0.8315 | Test score: 0.8369\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4138\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.4006\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3283\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3809\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3533\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3679\n",
      "Epoch 010 | Validation score: 0.8326 | Test score: 0.8385\n",
      "(epoch) 1 (batch) 0 (loss) 0.7523\n",
      "(epoch) 1 (batch) 16 (loss) 0.7147\n",
      "(epoch) 1 (batch) 32 (loss) 0.6757\n",
      "(epoch) 1 (batch) 48 (loss) 0.6588\n",
      "(epoch) 1 (batch) 64 (loss) 0.6142\n",
      "(epoch) 1 (batch) 80 (loss) 0.5695\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.5771\n",
      "(epoch) 2 (batch) 16 (loss) 0.5250\n",
      "(epoch) 2 (batch) 32 (loss) 0.4505\n",
      "(epoch) 2 (batch) 48 (loss) 0.4869\n",
      "(epoch) 2 (batch) 64 (loss) 0.4157\n",
      "(epoch) 2 (batch) 80 (loss) 0.4426\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4359\n",
      "(epoch) 3 (batch) 16 (loss) 0.4413\n",
      "(epoch) 3 (batch) 32 (loss) 0.3642\n",
      "(epoch) 3 (batch) 48 (loss) 0.4485\n",
      "(epoch) 3 (batch) 64 (loss) 0.3727\n",
      "(epoch) 3 (batch) 80 (loss) 0.4119\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4200\n",
      "(epoch) 4 (batch) 16 (loss) 0.4073\n",
      "(epoch) 4 (batch) 32 (loss) 0.3602\n",
      "(epoch) 4 (batch) 48 (loss) 0.4336\n",
      "(epoch) 4 (batch) 64 (loss) 0.3710\n",
      "(epoch) 4 (batch) 80 (loss) 0.3801\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4058\n",
      "(epoch) 5 (batch) 16 (loss) 0.4074\n",
      "(epoch) 5 (batch) 32 (loss) 0.3670\n",
      "(epoch) 5 (batch) 48 (loss) 0.4349\n",
      "(epoch) 5 (batch) 64 (loss) 0.3529\n",
      "(epoch) 5 (batch) 80 (loss) 0.3960\n",
      "Epoch 005 | Validation score: 0.8280 | Test score: 0.8263\n",
      "(epoch) 6 (batch) 0 (loss) 0.3953\n",
      "(epoch) 6 (batch) 16 (loss) 0.4085\n",
      "(epoch) 6 (batch) 32 (loss) 0.3623\n",
      "(epoch) 6 (batch) 48 (loss) 0.4025\n",
      "(epoch) 6 (batch) 64 (loss) 0.3492\n",
      "(epoch) 6 (batch) 80 (loss) 0.3852\n",
      "Epoch 006 | Validation score: 0.8344 | Test score: 0.8322\n",
      "(epoch) 7 (batch) 0 (loss) 0.4045\n",
      "(epoch) 7 (batch) 16 (loss) 0.3877\n",
      "(epoch) 7 (batch) 32 (loss) 0.3395\n",
      "(epoch) 7 (batch) 48 (loss) 0.4364\n",
      "(epoch) 7 (batch) 64 (loss) 0.3755\n",
      "(epoch) 7 (batch) 80 (loss) 0.3882\n",
      "Epoch 007 | Validation score: 0.8330 | Test score: 0.8328\n",
      "(epoch) 8 (batch) 0 (loss) 0.3855\n",
      "(epoch) 8 (batch) 16 (loss) 0.3936\n",
      "(epoch) 8 (batch) 32 (loss) 0.3459\n",
      "(epoch) 8 (batch) 48 (loss) 0.3788\n",
      "(epoch) 8 (batch) 64 (loss) 0.3642\n",
      "(epoch) 8 (batch) 80 (loss) 0.3562\n",
      "Epoch 008 | Validation score: 0.8321 | Test score: 0.8333\n",
      "(epoch) 9 (batch) 0 (loss) 0.4060\n",
      "(epoch) 9 (batch) 16 (loss) 0.3967\n",
      "(epoch) 9 (batch) 32 (loss) 0.3480\n",
      "(epoch) 9 (batch) 48 (loss) 0.4264\n",
      "(epoch) 9 (batch) 64 (loss) 0.3590\n",
      "(epoch) 9 (batch) 80 (loss) 0.3416\n",
      "Epoch 009 | Validation score: 0.8336 | Test score: 0.8326\n",
      "(epoch) 10 (batch) 0 (loss) 0.4055\n",
      "(epoch) 10 (batch) 16 (loss) 0.4063\n",
      "(epoch) 10 (batch) 32 (loss) 0.3524\n",
      "(epoch) 10 (batch) 48 (loss) 0.3851\n",
      "(epoch) 10 (batch) 64 (loss) 0.3410\n",
      "(epoch) 10 (batch) 80 (loss) 0.3822\n",
      "Epoch 010 | Validation score: 0.8338 | Test score: 0.8357\n",
      "(epoch) 1 (relational-batch) 0 (loss) 0.9092\n",
      "(epoch) 1 (relational-batch) 16 (loss) 0.8753\n",
      "(epoch) 1 (relational-batch) 32 (loss) 0.8623\n",
      "(epoch) 1 (relational-batch) 48 (loss) 0.8139\n",
      "(epoch) 1 (relational-batch) 64 (loss) 0.8001\n",
      "(epoch) 1 (relational-batch) 80 (loss) 0.7536\n",
      "Epoch 001 | Validation score: 0.2534 | Test score: 0.2477\n",
      "(epoch) 2 (relational-batch) 0 (loss) 0.7528\n",
      "(epoch) 2 (relational-batch) 16 (loss) 0.7066\n",
      "(epoch) 2 (relational-batch) 32 (loss) 0.6285\n",
      "(epoch) 2 (relational-batch) 48 (loss) 0.5825\n",
      "(epoch) 2 (relational-batch) 64 (loss) 0.5072\n",
      "(epoch) 2 (relational-batch) 80 (loss) 0.4967\n",
      "Epoch 002 | Validation score: 0.7927 | Test score: 0.8012\n",
      "(epoch) 3 (relational-batch) 0 (loss) 0.4498\n",
      "(epoch) 3 (relational-batch) 16 (loss) 0.4222\n",
      "(epoch) 3 (relational-batch) 32 (loss) 0.3746\n",
      "(epoch) 3 (relational-batch) 48 (loss) 0.4363\n",
      "(epoch) 3 (relational-batch) 64 (loss) 0.3721\n",
      "(epoch) 3 (relational-batch) 80 (loss) 0.4319\n",
      "Epoch 003 | Validation score: 0.8299 | Test score: 0.8334\n",
      "(epoch) 4 (relational-batch) 0 (loss) 0.4312\n",
      "(epoch) 4 (relational-batch) 16 (loss) 0.4082\n",
      "(epoch) 4 (relational-batch) 32 (loss) 0.3649\n",
      "(epoch) 4 (relational-batch) 48 (loss) 0.3803\n",
      "(epoch) 4 (relational-batch) 64 (loss) 0.3576\n",
      "(epoch) 4 (relational-batch) 80 (loss) 0.4089\n",
      "Epoch 004 | Validation score: 0.8336 | Test score: 0.8357\n",
      "(epoch) 5 (relational-batch) 0 (loss) 0.4025\n",
      "(epoch) 5 (relational-batch) 16 (loss) 0.4046\n",
      "(epoch) 5 (relational-batch) 32 (loss) 0.3595\n",
      "(epoch) 5 (relational-batch) 48 (loss) 0.3942\n",
      "(epoch) 5 (relational-batch) 64 (loss) 0.3647\n",
      "(epoch) 5 (relational-batch) 80 (loss) 0.3738\n",
      "Epoch 005 | Validation score: 0.8334 | Test score: 0.8368\n",
      "(epoch) 6 (relational-batch) 0 (loss) 0.4111\n",
      "(epoch) 6 (relational-batch) 16 (loss) 0.3822\n",
      "(epoch) 6 (relational-batch) 32 (loss) 0.3588\n",
      "(epoch) 6 (relational-batch) 48 (loss) 0.3771\n",
      "(epoch) 6 (relational-batch) 64 (loss) 0.3517\n",
      "(epoch) 6 (relational-batch) 80 (loss) 0.3706\n",
      "Epoch 006 | Validation score: 0.8326 | Test score: 0.8371\n",
      "(epoch) 7 (relational-batch) 0 (loss) 0.4225\n",
      "(epoch) 7 (relational-batch) 16 (loss) 0.3813\n",
      "(epoch) 7 (relational-batch) 32 (loss) 0.3591\n",
      "(epoch) 7 (relational-batch) 48 (loss) 0.3824\n",
      "(epoch) 7 (relational-batch) 64 (loss) 0.3633\n",
      "(epoch) 7 (relational-batch) 80 (loss) 0.3801\n",
      "Epoch 007 | Validation score: 0.8328 | Test score: 0.8363\n",
      "(epoch) 8 (relational-batch) 0 (loss) 0.3957\n",
      "(epoch) 8 (relational-batch) 16 (loss) 0.3862\n",
      "(epoch) 8 (relational-batch) 32 (loss) 0.3472\n",
      "(epoch) 8 (relational-batch) 48 (loss) 0.3913\n",
      "(epoch) 8 (relational-batch) 64 (loss) 0.3534\n",
      "(epoch) 8 (relational-batch) 80 (loss) 0.3829\n",
      "Epoch 008 | Validation score: 0.8313 | Test score: 0.8363\n",
      "(epoch) 9 (relational-batch) 0 (loss) 0.4290\n",
      "(epoch) 9 (relational-batch) 16 (loss) 0.3674\n",
      "(epoch) 9 (relational-batch) 32 (loss) 0.3537\n",
      "(epoch) 9 (relational-batch) 48 (loss) 0.3806\n",
      "(epoch) 9 (relational-batch) 64 (loss) 0.3445\n",
      "(epoch) 9 (relational-batch) 80 (loss) 0.3755\n",
      "Epoch 009 | Validation score: 0.8324 | Test score: 0.8376\n",
      "(epoch) 10 (relational-batch) 0 (loss) 0.4239\n",
      "(epoch) 10 (relational-batch) 16 (loss) 0.3856\n",
      "(epoch) 10 (relational-batch) 32 (loss) 0.3510\n",
      "(epoch) 10 (relational-batch) 48 (loss) 0.3747\n",
      "(epoch) 10 (relational-batch) 64 (loss) 0.3438\n",
      "(epoch) 10 (relational-batch) 80 (loss) 0.3837\n",
      "Epoch 010 | Validation score: 0.8328 | Test score: 0.8362\n",
      "(epoch) 1 (batch) 0 (loss) 0.5993\n",
      "(epoch) 1 (batch) 16 (loss) 0.5882\n",
      "(epoch) 1 (batch) 32 (loss) 0.5473\n",
      "(epoch) 1 (batch) 48 (loss) 0.5588\n",
      "(epoch) 1 (batch) 64 (loss) 0.4961\n",
      "(epoch) 1 (batch) 80 (loss) 0.5032\n",
      "Epoch 001 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 2 (batch) 0 (loss) 0.5024\n",
      "(epoch) 2 (batch) 16 (loss) 0.4682\n",
      "(epoch) 2 (batch) 32 (loss) 0.4231\n",
      "(epoch) 2 (batch) 48 (loss) 0.4743\n",
      "(epoch) 2 (batch) 64 (loss) 0.4186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch) 2 (batch) 80 (loss) 0.4358\n",
      "Epoch 002 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 3 (batch) 0 (loss) 0.4379\n",
      "(epoch) 3 (batch) 16 (loss) 0.4131\n",
      "(epoch) 3 (batch) 32 (loss) 0.4017\n",
      "(epoch) 3 (batch) 48 (loss) 0.4566\n",
      "(epoch) 3 (batch) 64 (loss) 0.3931\n",
      "(epoch) 3 (batch) 80 (loss) 0.4168\n",
      "Epoch 003 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 4 (batch) 0 (loss) 0.4408\n",
      "(epoch) 4 (batch) 16 (loss) 0.4143\n",
      "(epoch) 4 (batch) 32 (loss) 0.3703\n",
      "(epoch) 4 (batch) 48 (loss) 0.4358\n",
      "(epoch) 4 (batch) 64 (loss) 0.3731\n",
      "(epoch) 4 (batch) 80 (loss) 0.4010\n",
      "Epoch 004 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 5 (batch) 0 (loss) 0.4127\n",
      "(epoch) 5 (batch) 16 (loss) 0.4087\n",
      "(epoch) 5 (batch) 32 (loss) 0.3673\n",
      "(epoch) 5 (batch) 48 (loss) 0.4069\n",
      "(epoch) 5 (batch) 64 (loss) 0.3667\n",
      "(epoch) 5 (batch) 80 (loss) 0.3860\n",
      "Epoch 005 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 6 (batch) 0 (loss) 0.4032\n",
      "(epoch) 6 (batch) 16 (loss) 0.3936\n",
      "(epoch) 6 (batch) 32 (loss) 0.3610\n",
      "(epoch) 6 (batch) 48 (loss) 0.4172\n",
      "(epoch) 6 (batch) 64 (loss) 0.3408\n",
      "(epoch) 6 (batch) 80 (loss) 0.3884\n",
      "Epoch 006 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 7 (batch) 0 (loss) 0.4145\n",
      "(epoch) 7 (batch) 16 (loss) 0.3931\n",
      "(epoch) 7 (batch) 32 (loss) 0.3540\n",
      "(epoch) 7 (batch) 48 (loss) 0.4022\n",
      "(epoch) 7 (batch) 64 (loss) 0.3563\n",
      "(epoch) 7 (batch) 80 (loss) 0.3750\n",
      "Epoch 007 | Validation score: 0.7518 | Test score: 0.7606\n",
      "(epoch) 8 (batch) 0 (loss) 0.4366\n",
      "(epoch) 8 (batch) 16 (loss) 0.3739\n",
      "(epoch) 8 (batch) 32 (loss) 0.3369\n",
      "(epoch) 8 (batch) 48 (loss) 0.4220\n",
      "(epoch) 8 (batch) 64 (loss) 0.3442\n",
      "(epoch) 8 (batch) 80 (loss) 0.3911\n",
      "Epoch 008 | Validation score: 0.7518 | Test score: 0.7606\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "results[\"rb\"] = []\n",
    "results[\"norb\"] = []\n",
    "k = 10\n",
    "for _ in range(k):\n",
    "    model, optimizer, loss_fn = createModel()\n",
    "    relational_batch = True\n",
    "    losses = learnThat(\n",
    "        _model    =model, \n",
    "        _optimizer=optimizer, \n",
    "        _loss_fn  =loss_fn, \n",
    "        _evaluate =evaluate, \n",
    "        _progress =progress,\n",
    "        _X=X, \n",
    "        _y=y, \n",
    "        _epochs      =epochs, \n",
    "        _batch_size  =batch_size,\n",
    "        _train_loader=train_loader, \n",
    "        _relational_batch=relational_batch, \n",
    "        _old_X=oldX,\n",
    "        print_mode=False)\n",
    "    results[\"rb\"].append(losses[\"test\"])\n",
    "    \n",
    "    model, optimizer, loss_fn = createModel()\n",
    "    relational_batch = False\n",
    "    losses = learnThat(\n",
    "        _model    =model, \n",
    "        _optimizer=optimizer, \n",
    "        _loss_fn  =loss_fn, \n",
    "        _evaluate =evaluate, \n",
    "        _progress =progress,\n",
    "        _X=X, \n",
    "        _y=y, \n",
    "        _epochs      =epochs, \n",
    "        _batch_size  =batch_size,\n",
    "        _train_loader=train_loader, \n",
    "        _relational_batch=relational_batch, \n",
    "        _old_X=oldX,\n",
    "        print_mode=False)\n",
    "    results[\"norb\"].append(losses[\"test\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-advantage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
